{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relavant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Cement  BF_slag  Fly_ash  Water  Super_plasticizer  Coarse_aggregate  \\\n",
       "0   540.0      0.0      0.0  162.0                2.5            1040.0   \n",
       "1   540.0      0.0      0.0  162.0                2.5            1055.0   \n",
       "2   332.5    142.5      0.0  228.0                0.0             932.0   \n",
       "3   332.5    142.5      0.0  228.0                0.0             932.0   \n",
       "4   198.6    132.4      0.0  192.0                0.0             978.4   \n",
       "\n",
       "   Fine_aggregate  Age   Comp_str  \n",
       "0           676.0   28  79.986111  \n",
       "1           676.0   28  61.887366  \n",
       "2           594.0  270  40.269535  \n",
       "3           594.0  365  41.052780  \n",
       "4           825.5  360  44.296075  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>BF_slag</th>\n      <th>Fly_ash</th>\n      <th>Water</th>\n      <th>Super_plasticizer</th>\n      <th>Coarse_aggregate</th>\n      <th>Fine_aggregate</th>\n      <th>Age</th>\n      <th>Comp_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.986111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.887366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.269535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.052780</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.296075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "concrete = pd.read_excel(\"Concrete.xlsx\")\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1030 entries, 0 to 1029\nData columns (total 9 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Cement             1030 non-null   float64\n 1   BF_slag            1030 non-null   float64\n 2   Fly_ash            1030 non-null   float64\n 3   Water              1030 non-null   float64\n 4   Super_plasticizer  1030 non-null   float64\n 5   Coarse_aggregate   1030 non-null   float64\n 6   Fine_aggregate     1030 non-null   float64\n 7   Age                1030 non-null   int64  \n 8   Comp_str           1030 non-null   float64\ndtypes: float64(8), int64(1)\nmemory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "concrete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Cement      BF_slag      Fly_ash        Water  Super_plasticizer  \\\n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000        1030.000000   \n",
       "mean    281.165631    73.895485    54.187136   181.566359           6.203112   \n",
       "std     104.507142    86.279104    63.996469    21.355567           5.973492   \n",
       "min     102.000000     0.000000     0.000000   121.750000           0.000000   \n",
       "25%     192.375000     0.000000     0.000000   164.900000           0.000000   \n",
       "50%     272.900000    22.000000     0.000000   185.000000           6.350000   \n",
       "75%     350.000000   142.950000   118.270000   192.000000          10.160000   \n",
       "max     540.000000   359.400000   200.100000   247.000000          32.200000   \n",
       "\n",
       "       Coarse_aggregate  Fine_aggregate          Age     Comp_str  \n",
       "count       1030.000000     1030.000000  1030.000000  1030.000000  \n",
       "mean         972.918592      773.578883    45.662136    35.817836  \n",
       "std           77.753818       80.175427    63.169912    16.705679  \n",
       "min          801.000000      594.000000     1.000000     2.331808  \n",
       "25%          932.000000      730.950000     7.000000    23.707115  \n",
       "50%          968.000000      779.510000    28.000000    34.442774  \n",
       "75%         1029.400000      824.000000    56.000000    46.136287  \n",
       "max         1145.000000      992.600000   365.000000    82.599225  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>BF_slag</th>\n      <th>Fly_ash</th>\n      <th>Water</th>\n      <th>Super_plasticizer</th>\n      <th>Coarse_aggregate</th>\n      <th>Fine_aggregate</th>\n      <th>Age</th>\n      <th>Comp_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n      <td>1030.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>281.165631</td>\n      <td>73.895485</td>\n      <td>54.187136</td>\n      <td>181.566359</td>\n      <td>6.203112</td>\n      <td>972.918592</td>\n      <td>773.578883</td>\n      <td>45.662136</td>\n      <td>35.817836</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>104.507142</td>\n      <td>86.279104</td>\n      <td>63.996469</td>\n      <td>21.355567</td>\n      <td>5.973492</td>\n      <td>77.753818</td>\n      <td>80.175427</td>\n      <td>63.169912</td>\n      <td>16.705679</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>102.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>121.750000</td>\n      <td>0.000000</td>\n      <td>801.000000</td>\n      <td>594.000000</td>\n      <td>1.000000</td>\n      <td>2.331808</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>192.375000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>164.900000</td>\n      <td>0.000000</td>\n      <td>932.000000</td>\n      <td>730.950000</td>\n      <td>7.000000</td>\n      <td>23.707115</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>272.900000</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>185.000000</td>\n      <td>6.350000</td>\n      <td>968.000000</td>\n      <td>779.510000</td>\n      <td>28.000000</td>\n      <td>34.442774</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>350.000000</td>\n      <td>142.950000</td>\n      <td>118.270000</td>\n      <td>192.000000</td>\n      <td>10.160000</td>\n      <td>1029.400000</td>\n      <td>824.000000</td>\n      <td>56.000000</td>\n      <td>46.136287</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>540.000000</td>\n      <td>359.400000</td>\n      <td>200.100000</td>\n      <td>247.000000</td>\n      <td>32.200000</td>\n      <td>1145.000000</td>\n      <td>992.600000</td>\n      <td>365.000000</td>\n      <td>82.599225</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "concrete.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1030, 8)\n(1030,)\n"
     ]
    }
   ],
   "source": [
    "X = concrete.drop(\"Comp_str\", axis = 1)\n",
    "y = concrete[\"Comp_str\"]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GridSearchCV(cv=10, estimator=GradientBoostingRegressor(criterion='mae'),\n             n_jobs=4,\n             param_grid={'criterion': ['friedman_mse', 'mse', 'mae'],\n                         'max_depth': [2, 4, 8, 10, 12],\n                         'max_features': ['auto', 'sqrt'],\n                         'n_estimators': [100, 200, 300]},\n             return_train_score=True, scoring='neg_mean_absolute_error')\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier with specified criterion\n",
    "gb_regressor = GradientBoostingRegressor(criterion = \"mae\")\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'max_depth' : [2, 4, 8, 10, 12],\n",
    "              'n_estimators' : [100, 200, 300],\n",
    "              'max_features' : ['auto', 'sqrt'],\n",
    "              \"criterion\" : [\"friedman_mse\", \"mse\", \"mae\"]} \n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_gb = GridSearchCV(\n",
    "    estimator = gb_regressor,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = 4,\n",
    "    cv = 10,\n",
    "    refit = True,\n",
    "    return_train_score = True)\n",
    "\n",
    "print(grid_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingRegressor(criterion='mae'),\n",
       "             n_jobs=4,\n",
       "             param_grid={'criterion': ['friedman_mse', 'mse', 'mae'],\n",
       "                         'max_depth': [2, 4, 8, 10, 12],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "grid_gb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 300}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "grid_gb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-2.9084712007676776"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "grid_gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n11       0.300672      0.011414         0.002689        0.001341   \n\n   param_criterion param_max_depth param_max_features param_n_estimators  \\\n11    friedman_mse               4               sqrt                300   \n\n                                               params  split0_test_score  ...  \\\n11  {'criterion': 'friedman_mse', 'max_depth': 4, ...          -2.968202  ...   \n\n    split2_train_score  split3_train_score  split4_train_score  \\\n11           -1.161659           -1.121162           -1.126631   \n\n    split5_train_score  split6_train_score  split7_train_score  \\\n11           -1.145858           -1.162898           -1.197257   \n\n    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n11           -1.140079           -1.176149         -1.161242         0.027253  \n\n[1 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_gb.cv_results_)\n",
    "\n",
    "# Extract and print the row that had the best mean test score\n",
    "best_row = cv_results[cv_results['rank_test_score'] == 1]\n",
    "print(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       0.300672      0.011414         0.002689        0.001341   \n",
       "\n",
       "   param_criterion param_max_depth param_max_features param_n_estimators  \\\n",
       "11    friedman_mse               4               sqrt                300   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "11  {'criterion': 'friedman_mse', 'max_depth': 4, ...          -2.968202  ...   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "11           -1.161659           -1.121162           -1.126631   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "11           -1.145858           -1.162898           -1.197257   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "11           -1.140079           -1.176149         -1.161242         0.027253  \n",
       "\n",
       "[1 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_criterion</th>\n      <th>param_max_depth</th>\n      <th>param_max_features</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>...</th>\n      <th>split2_train_score</th>\n      <th>split3_train_score</th>\n      <th>split4_train_score</th>\n      <th>split5_train_score</th>\n      <th>split6_train_score</th>\n      <th>split7_train_score</th>\n      <th>split8_train_score</th>\n      <th>split9_train_score</th>\n      <th>mean_train_score</th>\n      <th>std_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>0.300672</td>\n      <td>0.011414</td>\n      <td>0.002689</td>\n      <td>0.001341</td>\n      <td>friedman_mse</td>\n      <td>4</td>\n      <td>sqrt</td>\n      <td>300</td>\n      <td>{'criterion': 'friedman_mse', 'max_depth': 4, ...</td>\n      <td>-2.968202</td>\n      <td>...</td>\n      <td>-1.161659</td>\n      <td>-1.121162</td>\n      <td>-1.126631</td>\n      <td>-1.145858</td>\n      <td>-1.162898</td>\n      <td>-1.197257</td>\n      <td>-1.140079</td>\n      <td>-1.176149</td>\n      <td>-1.161242</td>\n      <td>0.027253</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "cv_results.loc[[grid_gb.best_index_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "grid_gb.best_params_[\"n_estimators\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_gb.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.8632340005272474"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(criterion='mae'),\n                   n_jobs=4,\n                   param_distributions={'criterion': ['friedman_mse', 'mse',\n                                                      'mae'],\n                                        'max_depth': [2, 4, 8, 10, 12],\n                                        'max_features': ['auto', 'sqrt'],\n                                        'n_estimators': [100, 200, 300]},\n                   return_train_score=True, scoring='neg_mean_absolute_error')\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier with specified criterion\n",
    "gb_regressor = GradientBoostingRegressor(criterion = \"mae\")\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'max_depth' : [2, 4, 8, 10, 12],\n",
    "              'n_estimators' : [100, 200, 300],\n",
    "              'max_features' : ['auto', 'sqrt'],\n",
    "              \"criterion\" : [\"friedman_mse\", \"mse\", \"mae\"]} \n",
    "\n",
    "# Create a GridSearchCV object\n",
    "random_grid_gb = RandomizedSearchCV(\n",
    "    estimator = gb_regressor,\n",
    "    param_distributions = param_grid,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = 4,\n",
    "    cv = 10,\n",
    "    refit = True, return_train_score = True)\n",
    "print(random_grid_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(criterion='mae'),\n",
       "                   n_jobs=4,\n",
       "                   param_distributions={'criterion': ['friedman_mse', 'mse',\n",
       "                                                      'mae'],\n",
       "                                        'max_depth': [2, 4, 8, 10, 12],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "random_grid_gb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[4 8 2 12 10 12 2 12 10 8]\n[300 300 200 100 300 300 300 100 300 300]\n"
     ]
    }
   ],
   "source": [
    "print(random_grid_gb.cv_results_['param_max_depth'])\n",
    "print(random_grid_gb.cv_results_['param_n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 8,\n",
       " 'criterion': 'mae'}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "random_grid_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-2.9905477926610717"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "random_grid_gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = random_grid_gb.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.994156945716245"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization Progress:   5%|▌         | 11/210 [00:16<22:17,  6.72s/pipeline]\n",
      "Optimization Progress:  10%|█         | 22/210 [00:21<12:26,  3.97s/pipeline]\n",
      "Optimization Progress:  16%|█▌        | 33/210 [00:39<10:58,  3.72s/pipeline]\n",
      "Optimization Progress:  20%|██        | 42/210 [00:55<11:20,  4.05s/pipeline]\n",
      "Optimization Progress:  25%|██▌       | 53/210 [01:00<06:22,  2.44s/pipeline]\n",
      "Optimization Progress:  30%|██▉       | 62/210 [01:09<06:12,  2.52s/pipeline]\n",
      "Optimization Progress:  34%|███▍      | 72/210 [01:14<04:13,  1.84s/pipeline]\n",
      "Optimization Progress:  39%|███▉      | 82/210 [01:30<06:59,  3.27s/pipeline]\n",
      "Optimization Progress:  43%|████▎     | 91/210 [01:40<08:51,  4.47s/pipeline]\n",
      "Optimization Progress:  48%|████▊     | 101/210 [01:47<07:22,  4.06s/pipeline]\n",
      "Optimization Progress:  53%|█████▎    | 111/210 [01:52<05:28,  3.32s/pipeline]\n",
      "Optimization Progress:  58%|█████▊    | 121/210 [01:58<04:39,  3.14s/pipeline]\n",
      "Optimization Progress:  63%|██████▎   | 132/210 [02:02<02:45,  2.13s/pipeline]\n",
      "Optimization Progress:  68%|██████▊   | 142/210 [02:07<01:52,  1.65s/pipeline]\n",
      "Optimization Progress:  72%|███████▏  | 152/210 [02:11<01:21,  1.41s/pipeline]\n",
      "Optimization Progress:  77%|███████▋  | 162/210 [02:14<00:52,  1.10s/pipeline]\n",
      "Optimization Progress:  82%|████████▏ | 173/210 [02:17<00:31,  1.19pipeline/s]\n",
      "Optimization Progress:  87%|████████▋ | 182/210 [02:22<00:32,  1.14s/pipeline]\n",
      "Optimization Progress:  91%|█████████▏| 192/210 [02:35<00:42,  2.37s/pipeline]\n",
      "Optimization Progress:  96%|█████████▌| 202/210 [02:38<00:12,  1.58s/pipeline]\n",
      "                                                                              \n",
      "Best pipeline: XGBRegressor(MinMaxScaler(input_matrix), learning_rate=0.1, max_depth=8, min_child_weight=4, n_estimators=100, nthread=1, objective=reg:squarederror, subsample=0.6000000000000001)\n",
      "-2.8526538220688846\n"
     ]
    }
   ],
   "source": [
    "# Assign the values outlined to the inputs\n",
    "number_generations = 20\n",
    "population_size = 10\n",
    "offspring_size = 10\n",
    "scoring_function = 'neg_mean_absolute_error'\n",
    "\n",
    "# Create the tpot classifier\n",
    "tpot_clf = TPOTRegressor(generations = number_generations,\n",
    "                         population_size = population_size,\n",
    "                         offspring_size = offspring_size,\n",
    "                         scoring = scoring_function,\n",
    "                         verbosity = 2,\n",
    "                         random_state = 2,\n",
    "                         cv = 10,\n",
    "                         n_jobs = -1)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}